{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3sf3klkb23N"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import os\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY') # add your OpenAI API Key\n",
        "\n",
        "\n",
        "DOC_PATH = \"your.pdf\"\n",
        "CHROMA_PATH = \"your_db_name\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ----- Data Indexing Process -----\n",
        "\n",
        "# load your pdf doc\n",
        "loader = PyPDFLoader(DOC_PATH)\n",
        "pages = loader.load()\n",
        "\n",
        "# split the doc into smaller chunks i.e. chunk_size=500\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "chunks = text_splitter.split_documents(pages)\n",
        "\n",
        "# get OpenAI Embedding model\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
        "\n",
        "# embed the chunks as vectors and load them into the database\n",
        "db_chroma = Chroma.from_documents(chunks, embeddings, persist_directory=CHROMA_PATH)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ----- Retrieval and Generation Process -----\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# this is an example of a user question (query)\n",
        "query = 'what are the top risks mentioned in the document?'\n",
        "\n",
        "# retrieve context - top 5 most relevant (closests) chunks to the query vector\n",
        "# (by default Langchain is using cosine distance metric)\n",
        "docs_chroma = db_chroma.similarity_search_with_score(query, k=5)\n",
        "\n",
        "# generate an answer based on given user query and retrieved context information\n",
        "context_text = \"\\n\\n\".join([doc.page_content for doc, _score in docs_chroma])\n",
        "\n",
        "# you can use a prompt template\n",
        "PROMPT_TEMPLATE = \"\"\"\n",
        "Answer the question based only on the following context:\n",
        "{context}\n",
        "Answer the question based on the above context: {question}.\n",
        "Provide a detailed answer.\n",
        "Don’t justify your answers.\n",
        "Don’t give information not mentioned in the CONTEXT INFORMATION.\n",
        "Do not say \"according to the context\" or \"mentioned in the context\" or similar.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# load retrieved context and user query in the prompt template\n",
        "prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
        "prompt = prompt_template.format(context=context_text, question=query)\n",
        "\n",
        "# call LLM model to generate the answer based on the given context and query\n",
        "model = ChatOpenAI()\n",
        "response_text = model.predict(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zYtMSFpJBLYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JyMtRls4BqEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oV28qI-MBqHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# second example"
      ],
      "metadata": {
        "id": "NI79kJrwBqKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "pdf = PyPDFLoader (\"/Users/myhome/Downloads/llmops/Catalogue.pdf\")\n",
        "\n",
        "pdfpages = pdf.load_and_split()\n",
        "\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_community. vectorstores import FAISS\n",
        "\n",
        "from langchain_openai.embeddings import OpenAIEmbeddings\n",
        "\n",
        "import os\n",
        "\n",
        "from langchain_openai import OpenAI\n",
        "\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"]=api_key\n"
      ],
      "metadata": {
        "id": "rWausDElBLa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#indexxing\n",
        "mybooks = pdf.load ()\n",
        "\n",
        "text_splitter = CharacterTextSplitter (chunk_size=1500, chunk_overlap=0)\n",
        "\n",
        "split_text = text_splitter.split_documents (mybooks)\n",
        "\n",
        "embeddings = OpenAIEmbeddings()\n",
        "vectorstore = FAISS.from_documents(split_text, embeddings)\n"
      ],
      "metadata": {
        "id": "VCTrPHpuBLc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# retrival. and generatiion\n",
        "vectorstore_retriever = vectorstore.as_retriever()\n",
        "\n",
        "from langchain.agents.agent_toolkits import create_retriever_tool\n",
        "\n",
        "tool = create_retriever_tool(\n",
        "    vectorstore_retriever,\n",
        "\n",
        "    \"catalogue_pdf\",\n",
        "    \"Retrieve detailed information on title and language here which title is related to which language .\"\n",
        ")\n",
        "\n",
        "tools = [tool]\n",
        "\n",
        "from langchain.agents.agent_toolkits import create_conversational_retrieval_agent\n",
        "\n",
        "from langchain_openai.chat_models import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(temperature = 0, model_name=\"gpt-3.5-turbo\")\n",
        "\n",
        "myagent = create_conversational_retrieval_agent(llm, tools, verbose=True)"
      ],
      "metadata": {
        "id": "Vqs5VNznBLe6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "context = \"onl you have to give the answer of that book title  language fetch from the pdf .\"\n",
        "question = \"What is the language of the book title Banaras ke ghat \"\n",
        "\n",
        "prompt = f\"\"\"You need to answer the question in the sentence as same as in the pdf content.\n",
        "Given below is the context and question of the user.\n",
        "context = {context}\n",
        "question = {question}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "result = myagent.invoke({\"input\": prompt})"
      ],
      "metadata": {
        "id": "Hyj1twX8BLhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TPX9uqWuBLiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pqkctgRBBLk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pHubHzW9BLqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9Xlxtu1dBLsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mgo-AuqxBLtz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zkSf5kQmc6Kp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}